\sigma   ^ { 2 }
s ^ { 2 }
\operatorname   { V a r }   ( X )
X
X
{ \displaystyle   \mu   = \operatorname   { E }   [ X ] }
\operatorname   { V a r }   ( X ) = \operatorname   { E }   \left [ ( X - \mu   ) ^ { 2 } \right ] .
\operatorname   { V a r }   ( X ) = \operatorname   { C o v }   ( X , X ) .
X
\operatorname   { V a r }   ( X )
\sigma   _ { X } ^ { 2 }
\sigma   ^ { 2 }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X ) & = \operatorname   { E }   \left [ ( X - \operatorname   { E }   [ X ] ) ^ { 2 } \right ] \\[4pt ] & = \operatorname   { E }   \left [ X ^ { 2 } - 2 X \operatorname   { E }   [ X ] + \operatorname   { E }   [ X ] ^ { 2 } \right ] \\[4pt ] & = \operatorname   { E }   \left [ X ^ { 2 } \right ] - 2 \operatorname   { E }   [ X ] \operatorname   { E }   [ X ] + \operatorname   { E }   [ X ] ^ { 2 } \\[4pt ] & = \operatorname   { E }   \left [ X ^ { 2 } \right ] - \operatorname   { E }   [ X ] ^ { 2 } \end { a l i g n e d } } }
X
{ \displaystyle   x _ { 1 } \mapsto   p _ { 1 } , x _ { 2 } \mapsto   p _ { 2 } , \ldots   , x _ { n } \mapsto   p _ { n } }
\operatorname   { V a r }   ( X ) = \sum   _ { i = 1 } ^ { n } p _ { i } \cdot   ( x _ { i } - \mu   ) ^ { 2 } ,
{ \displaystyle   \operatorname   { V a r }   ( X ) = \left ( \sum   _ { i = 1 } ^ { n } p _ { i } x _ { i } ^ { 2 } \right ) - \mu   ^ { 2 } , }
\mu  
{ \displaystyle   \mu   = \sum   _ { i = 1 } ^ { n } p _ { i } x _ { i } . }
n
{ \displaystyle   \operatorname   { V a r }   ( X ) = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } ( x _ { i } - \mu   ) ^ { 2 } , }
\mu  
{ \displaystyle   \mu   = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } x _ { i } . }
n
\operatorname   { V a r }   ( X ) = { \frac   { 1 } { n ^ { 2 } } } \sum   _ { i = 1 } ^ { n } \sum   _ { j = 1 } ^ { n } { \frac   { 1 } { 2 } } ( x _ { i } - x _ { j } ) ^ { 2 } = { \frac   { 1 } { n ^ { 2 } } } \sum   _ { i } \sum   _ { j > i } ( x _ { i } - x _ { j } ) ^ { 2 } .
X
f ( x )
F ( x )
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X ) = \sigma   ^ { 2 } & = \int   ( x - \mu   ) ^ { 2 } f ( x ) \,dx \\[4pt ] & = \int   x ^ { 2 } f ( x ) \,dx - 2 \mu   \int   x f ( x ) \,dx + \int   \mu   ^ { 2 } f ( x ) \,dx \\[4pt ] & = \int   x ^ { 2 } \,dF ( x ) - 2 \mu   \int   x \,dF ( x ) + \mu   ^ { 2 } \int   \,dF ( x ) \\[4pt ] & = \int   x ^ { 2 } \,dF ( x ) - 2 \mu   \cdot   \mu   + \mu   ^ { 2 } \cdot   1 \\[4pt ] & = \int   x ^ { 2 } \,dF ( x ) - \mu   ^ { 2 } , \end { a l i g n e d } } }
{ \displaystyle   \operatorname   { V a r }   ( X ) = \int   x ^ { 2 } f ( x ) \,dx - \mu   ^ { 2 } , }
\mu  
X
{ \displaystyle   \mu   = \int   x f ( x ) \,dx = \int   x \,dF ( x ) , }
x
X .
k
{ \displaystyle   1 < k \leq   2 . }
\mu  
\sigma  
  f ( x )   =   \frac { 1 } { \sqrt { 2 \pi   \sigma ^ 2 } }   e ^ {   - \frac { ( x - \mu ) ^ 2 } { 2 \sigma ^ 2 }   } .  
{ \displaystyle   \operatorname   { E }   [ X ] = \mu   }
\operatorname   { V a r }   ( X )
\sigma  
{ \displaystyle   \operatorname   { V a r }   ( X ) = \int   _ { - \infty   } ^ { \infty   } { \frac   { x ^ { 2 } } { \sqrt   { 2 \pi   \sigma   ^ { 2 } } } } e ^ { - { \frac   { ( x - \mu   ) ^ { 2 } } { 2 \sigma   ^ { 2 } } } } \,dx - \mu   ^ { 2 } = \sigma   ^ { 2 } . }
\lambda  
[ 0 , \infty   )
{ \displaystyle   f ( x ) = \lambda   e ^ { - \lambda   x } }
{ \displaystyle   \mu   = \lambda   ^ { - 1 } }
{ \displaystyle   \operatorname   { V a r }   ( X ) = \int   _ { 0 } ^ { \infty   } x ^ { 2 } \lambda   e ^ { - \lambda   x } \,dx - \mu   ^ { 2 } = \lambda   ^ { - 2 } . }
{ \displaystyle   \sigma   ^ { 2 } = \mu   ^ { 2 } . }
\lambda  
{ \displaystyle   k = 0 , 1 , 2 , \ldots   }
p ( k ) = { \frac   { \lambda   ^ { k } } { k ! } } e ^ { - \lambda   } ,
{ \displaystyle   \mu   = \lambda   }
{ \displaystyle   \operatorname   { V a r }   ( X ) = \left ( \sum   _ { k = 0 } ^ { \infty   } k ^ { 2 } { \frac   { \lambda   ^ { k } } { k ! } } e ^ { - \lambda   } \right ) - \mu   ^ { 2 } = \lambda   , }
{ \displaystyle   \sigma   ^ { 2 } = \mu   }
n
p
{ \displaystyle   k = 0 , 1 , 2 , \ldots   , n }
p ( k ) = { n   \choose   k } p ^ { k } ( 1 - p ) ^ { n - k } ,
\mu   = n p
{ \displaystyle   \operatorname   { V a r }   ( X ) = \left ( \sum   _ { k = 0 } ^ { n } k ^ { 2 } { n   \choose   k } p ^ { k } ( 1 - p ) ^ { n - k } \right ) - \mu   ^ { 2 } = n p ( 1 - p ) . }
p = 1 / 2
k
n
{ \displaystyle   n / 2 , }
{ \displaystyle   n / 4 . }
{ \displaystyle   ( 1 + 2 + 3 + 4 + 5 + 6 ) / 6 = 7 / 2 . }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X ) & = \sum   _ { i = 1 } ^ { 6 } { \frac   { 1 } { 6 } } \left ( i - { \frac   { 7 } { 2 } } \right ) ^ { 2 } \\[5pt ] & = { \frac   { 1 } { 6 } } \left ( ( - 5 / 2 ) ^ { 2 } + ( - 3 / 2 ) ^ { 2 } + ( - 1 / 2 ) ^ { 2 } + ( 1 / 2 ) ^ { 2 } + ( 3 / 2 ) ^ { 2 } + ( 5 / 2 ) ^ { 2 } \right ) \\[5pt ] & = { \frac   { 3 5 } { 1 2 } } \approx   2 . 9 2 . \end { a l i g n e d } } }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X ) & = \operatorname   { E }   ( X ^ { 2 } ) - ( \operatorname   { E }   ( X ) ) ^ { 2 } \\[5pt ] & = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } i ^ { 2 } - \left ( { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } i \right ) ^ { 2 } \\[5pt ] & = { \frac   { ( n + 1 ) ( 2 n + 1 ) } { 6 } } - \left ( { \frac   { n + 1 } { 2 } } \right ) ^ { 2 } \\[4pt ] & = { \frac   { n ^ { 2 } - 1 } { 1 2 } } . \end { a l i g n e d } } }
\operatorname   { V a r }   ( X ) \geq   0 .
{ \displaystyle   P ( X = a ) = 1 \iff   \operatorname   { V a r }   ( X ) = 0 . }
\operatorname   { V a r }   ( X + a ) = \operatorname   { V a r }   ( X ) .
\operatorname   { V a r }   ( a X ) = a ^ { 2 } \operatorname   { V a r }   ( X ) .
\operatorname   { V a r }   ( a X + b Y ) = a ^ { 2 } \operatorname   { V a r }   ( X ) + b ^ { 2 } \operatorname   { V a r }   ( Y ) + 2 a b \,\operatorname   { C o v }   ( X , Y ) ,
\operatorname   { V a r }   ( a X - b Y ) = a ^ { 2 } \operatorname   { V a r }   ( X ) + b ^ { 2 } \operatorname   { V a r }   ( Y ) - 2 a b \,\operatorname   { C o v }   ( X , Y ) ,
N
\{ X _ { 1 } , \dots   , X _ { N } \ }
\operatorname   { V a r }   \left ( \sum   _ { i = 1 } ^ { N } X _ { i } \right ) = \sum   _ { i , j = 1 } ^ { N } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) = \sum   _ { i = 1 } ^ { N } \operatorname   { V a r }   ( X _ { i } ) + \sum   _ { i \neq   j } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) .
{ \begin { a l i g n e d } \operatorname   { V a r }   \left ( \sum   _ { i = 1 } ^ { N } a _ { i } X _ { i } \right ) & = \sum   _ { i , j = 1 } ^ { N } a _ { i } a _ { j } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) \\&=\sum   _ { i = 1 } ^ { N } a _ { i } ^ { 2 } \operatorname   { V a r }   ( X _ { i } ) + \sum   _ { i \not   = j } a _ { i } a _ { j } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) \\&=\sum   _ { i = 1 } ^ { N } a _ { i } ^ { 2 } \operatorname   { V a r }   ( X _ { i } ) + 2 \sum   _ { 1 \leq   i < j \leq   N } a _ { i } a _ { j } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) . \end { a l i g n e d } }
X _ { 1 } , \dots   , X _ { N }
\operatorname   { C o v }   ( X _ { i } , X _ { j } ) = 0 \ ,\ \forall   \ ( i \neq   j ) ,
X _ { 1 } , \dots   , X _ { N }
\operatorname   { V a r }   \left ( \sum   _ { i = 1 } ^ { N } X _ { i } \right ) = \sum   _ { i = 1 } ^ { N } \operatorname   { V a r }   ( X _ { i } ) .
X _ { 1 } , \dots   , X _ { n }
{ \displaystyle   \operatorname   { V a r }   \left ( \sum   _ { i = 1 } ^ { n } X _ { i } \right ) = \sum   _ { i = 1 } ^ { n } \operatorname   { V a r }   ( X _ { i } ) . }
{ \displaystyle   \operatorname   { V a r }   \left ( { \overline   { X } } \right ) = \operatorname   { V a r }   \left ( { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } X _ { i } \right ) = { \frac   { 1 } { n ^ { 2 } } } \sum   _ { i = 1 } ^ { n } \operatorname   { V a r }   \left ( X _ { i } \right ) = { \frac   { 1 } { n ^ { 2 } } } n \sigma   ^ { 2 } = { \frac   { \sigma   ^ { 2 } } { n } } . }
{ \displaystyle   \operatorname   { V a r }   ( X + Y ) = \operatorname   { V a r }   ( X ) + \operatorname   { V a r }   ( Y ) . }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X + Y ) & = \operatorname   { E }   [ ( X + Y ) ^ { 2 } ] - ( \operatorname   { E }   [ X + Y ] ) ^ { 2 } \\[5pt ] & = \operatorname   { E }   [ X ^ { 2 } + 2 X Y + Y ^ { 2 } ] - ( \operatorname   { E }   [ X ] + \operatorname   { E }   [ Y ] ) ^ { 2 } . \end { a l i g n e d } } }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X + Y ) & = \operatorname   { E }   [ X ^ { 2 } ] + 2 \operatorname   { E }   [ X Y ] + \operatorname   { E }   [ Y ^ { 2 } ] - ( \operatorname   { E }   [ X ] ^ { 2 } + 2 \operatorname   { E }   [ X ] \operatorname   { E }   [ Y ] + \operatorname   { E }   [ Y ] ^ { 2 } ) \\[5pt ] & = \operatorname   { E }   [ X ^ { 2 } ] + \operatorname   { E }   [ Y ^ { 2 } ] - \operatorname   { E }   [ X ] ^ { 2 } - \operatorname   { E }   [ Y ] ^ { 2 } \\[5pt ] & = \operatorname   { V a r }   ( X ) + \operatorname   { V a r }   ( Y ) . \end { a l i g n e d } } }
{ \displaystyle   \operatorname   { V a r }   \left ( \sum   _ { i = 1 } ^ { n } X _ { i } \right ) = \sum   _ { i = 1 } ^ { n } \sum   _ { j = 1 } ^ { n } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) = \sum   _ { i = 1 } ^ { n } \operatorname   { V a r }   ( X _ { i } ) + 2 \sum   _ { 1 \leq   i < j \leq   n } \operatorname   { C o v }   ( X _ { i } , X _ { j } ) . }
\operatorname   { V a r }   ( { \overline   { X } } ) = { \frac   { \sigma   ^ { 2 } } { n } } + { \frac   { n - 1 } { n } } \rho   \sigma   ^ { 2 } .
\operatorname   { V a r }   ( { \overline   { X } } ) = { \frac   { 1 } { n } } + { \frac   { n - 1 } { n } } \rho   .
\lim   _ { n \to   \infty   } \operatorname   { V a r }   ( { \overline   { X } } ) = \rho   .
X
n
X _ { 1 } , \ldots   , X _ { n }
c
n
c _ { 1 } , \ldots   , c _ { n }
c ^ { T } X
c ^ { T }
c
\Sigma  
X
c ^ { T } X
\operatorname   { V a r }   ( c ^ { T } X ) = c ^ { T } \Sigma   c .
{ \displaystyle   \operatorname   { V a r }   ( a X \pm   b Y ) = a ^ { 2 } \operatorname   { V a r }   ( X ) + b ^ { 2 } \operatorname   { V a r }   ( Y ) \pm   2 a b \,\operatorname   { C o v }   ( X , Y ) . }
\operatorname   { V a r }   \left ( \sum   _ { i } ^ { n } a _ { i } X _ { i } \right ) = \sum   _ { i = 1 } ^ { n } a _ { i } ^ { 2 } \operatorname   { V a r }   ( X _ { i } ) + 2 \sum   _ { 1 \leq   i } \sum   _ { < j \leq   n } a _ { i } a _ { j } \operatorname   { C o v }   ( X _ { i } , X _ { j } )
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X Y ) & = [ \operatorname   { E }   ( X ) ] ^ { 2 } \operatorname   { V a r }   ( Y ) + [ \operatorname   { E }   ( Y ) ] ^ { 2 } \operatorname   { V a r }   ( X ) + \operatorname   { V a r }   ( X ) \operatorname   { V a r }   ( Y ) . \end { a l i g n e d } } }
{ \displaystyle   \operatorname   { V a r }   ( X Y ) = \operatorname   { E }   ( X ^ { 2 } ) \operatorname   { E }   ( Y ^ { 2 } ) - [ \operatorname   { E }   ( X ) ] ^ { 2 } [ \operatorname   { E }   ( Y ) ] ^ { 2 } . }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { V a r }   ( X Y ) = { } & \operatorname   { E }   [ X ^ { 2 } Y ^ { 2 } ] - [ \operatorname   { E }   ( X Y ) ] ^ { 2 } \\[5pt ] = { } & \operatorname   { C o v }   ( X ^ { 2 } , Y ^ { 2 } ) + \operatorname   { E }   ( X ^ { 2 } ) \operatorname   { E }   ( Y ^ { 2 } ) - [ \operatorname   { E }   ( X Y ) ] ^ { 2 } \\[5pt ] = { } & \operatorname   { C o v }   ( X ^ { 2 } , Y ^ { 2 } ) + ( \operatorname   { V a r }   ( X ) + [ \operatorname   { E }   ( X ) ] ^ { 2 } ) ( \operatorname   { V a r }   ( Y ) + [ \operatorname   { E }   ( Y ) ] ^ { 2 } ) \\[5pt ] & { } - [ \operatorname   { C o v }   ( X , Y ) + \operatorname   { E }   ( X ) \operatorname   { E }   ( Y ) ] ^ { 2 } \end { a l i g n e d } } }
X
Y
X
{ \displaystyle   \operatorname   { V a r }   [ X ] = \operatorname   { E }   ( \operatorname   { V a r }   [ X \mid   Y ] ) + \operatorname   { V a r }   ( \operatorname   { E }   [ X \mid   Y ] ) . }
{ \displaystyle   \operatorname   { E }   ( X \mid   Y ) }
X
Y
{ \displaystyle   \operatorname   { V a r }   ( X \mid   Y ) }
{ \displaystyle   \operatorname   { E }   ( X \mid   Y = y ) }
{ \displaystyle   g ( y ) = \operatorname   { E }   ( X \mid   Y = y ) }
{ \displaystyle   \operatorname   { E }   ( X \mid   Y ) = g ( Y ) . }
Y
{ \displaystyle   y _ { 1 } , y _ { 2 } , y _ { 3 } \ldots   }
{ \displaystyle   p _ { 1 } , p _ { 2 } , p _ { 3 } \ldots   , }
{ \displaystyle   \operatorname   { E }   ( \operatorname   { V a r }   [ X \mid   Y ] ) = \sum   _ { i } p _ { i } \sigma   _ { i } ^ { 2 } , }
{ \displaystyle   \sigma   _ { i } ^ { 2 } = \operatorname   { V a r }   [ X \mid   Y = y _ { i } ] }
{ \displaystyle   \operatorname   { V a r }   ( \operatorname   { E }   [ X \mid   Y ] ) = \sum   _ { i } p _ { i } \mu   _ { i } ^ { 2 } - \left ( \sum   _ { i } p _ { i } \mu   _ { i } \right ) ^ { 2 } = \sum   _ { i } p _ { i } \mu   _ { i } ^ { 2 } - \mu   ^ { 2 } , }
{ \displaystyle   \mu   _ { i } = \operatorname   { E }   [ X \mid   Y = y _ { i } ] }
{ \displaystyle   \mu   = \sum   _ { i } p _ { i } \mu   _ { i } }
{ \displaystyle   \operatorname   { V a r }   [ X ] = \sum   _ { i } p _ { i } \sigma   _ { i } ^ { 2 } + \left ( \sum   _ { i } p _ { i } \mu   _ { i } ^ { 2 } - \mu   ^ { 2 } \right ) . }
{ \mathit   { M S } } _ { \text { t o t a l } } = { \mathit   { M S } } _ { \text { b e t w e e n } } + { \mathit   { M S } } _ { \text { w i t h i n } } ;
{ \mathit   { M S } }
{ \mathit   { M S } } _ { \text { t o t a l } } = { \mathit   { M S } } _ { \text { r e g r e s s i o n } } + { \mathit   { M S } } _ { \text { r e s i d u a l } } .
{ \mathit   { S S } }
{ \mathit   { S S } } _ { \text { t o t a l } } = { \mathit   { S S } } _ { \text { b e t w e e n } } + { \mathit   { S S } } _ { \text { w i t h i n } } ,
{ \mathit   { S S } } _ { \text { t o t a l } } = { \mathit   { S S } } _ { \text { r e g r e s s i o n } } + { \mathit   { S S } } _ { \text { r e s i d u a l } } .
\operatorname   { V a r }   ( X ) = \operatorname   { E }   ( X ^ { 2 } ) - ( \operatorname   { E }   ( X ) ) ^ { 2 } .
{ \displaystyle   2 \int   _ { 0 } ^ { \infty   } u ( 1 - F ( u ) ) \,du - { \Big   ( } \int   _ { 0 } ^ { \infty   } ( 1 - F ( u ) ) \,du { \Big   ) } ^ { 2 } . }
{ \displaystyle   \mathrm   { a r g m i n }   _ { m } \,\mathrm   { E }   \left ( \left ( X - m \right ) ^ { 2 } \right ) = \mathrm   { E }   ( X ) }
\varphi  
{ \displaystyle   \mathrm   { a r g m i n }   _ { m } \,\mathrm   { E }   ( \varphi   ( X - m ) ) = \mathrm   { E }   ( X ) }
\varphi   ( x ) = a x ^ { 2 } + b
\operatorname   { V a r }   \left [ f ( X ) \right ] \approx   \left ( f ' ( \operatorname   { E }   \left [ X \right ] ) \right ) ^ { 2 } \operatorname   { V a r }   \left [ X \right ]
{ \displaystyle   { \begin { a l i g n e d } \sigma   ^ { 2 } & = { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } \left ( x _ { i } - \mu   \right ) ^ { 2 } = { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } \left ( x _ { i } ^ { 2 } - 2 \mu   x _ { i } + \mu   ^ { 2 } \right ) \\[5pt ] & = \left ( { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } x _ { i } ^ { 2 } \right ) - 2 \mu   \left ( { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } x _ { i } \right ) + \mu   ^ { 2 } \\[5pt ] & = \left ( { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } x _ { i } ^ { 2 } \right ) - \mu   ^ { 2 } \end { a l i g n e d } } }
{ \displaystyle   \mu   = { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } x _ { i } . }
{ \displaystyle   \sigma   ^ { 2 } = { \frac   { 1 } { N ^ { 2 } } } \sum   _ { i < j } \left ( x _ { i } - x _ { j } \right ) ^ { 2 } = { \frac   { 1 } { 2 N ^ { 2 } } } \sum   _ { i , j = 1 } ^ { N } \left ( x _ { i } - x _ { j } \right ) ^ { 2 } . }
{ \displaystyle   { \begin { a l i g n e d } { \frac   { 1 } { 2 N ^ { 2 } } } \sum   _ { i , j = 1 } ^ { N } \left ( x _ { i } - x _ { j } \right ) ^ { 2 } & = { \frac   { 1 } { 2 N ^ { 2 } } } \sum   _ { i , j = 1 } ^ { N } \left ( x _ { i } ^ { 2 } - 2 x _ { i } x _ { j } + x _ { j } ^ { 2 } \right ) \\[5pt ] & = { \frac   { 1 } { 2 N } } \sum   _ { j = 1 } ^ { N } \left ( { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } x _ { i } ^ { 2 } \right ) - \left ( { \frac   { 1 } { N } } \sum   _ { i = 1 } ^ { N } x _ { i } \right ) \left ( { \frac   { 1 } { N } } \sum   _ { j = 1 } ^ { N } x _ { j } \right ) \\[5pt ] & \quad   + { \frac   { 1 } { 2 N } } \sum   _ { i = 1 } ^ { N } \left ( { \frac   { 1 } { N } } \sum   _ { j = 1 } ^ { N } x _ { j } ^ { 2 } \right ) \\[5pt ] & = { \frac   { 1 } { 2 } } \left ( \sigma   ^ { 2 } + \mu   ^ { 2 } \right ) - \mu   ^ { 2 } + { \frac   { 1 } { 2 } } \left ( \sigma   ^ { 2 } + \mu   ^ { 2 } \right ) \\[5pt ] & = \sigma   ^ { 2 } \end { a l i g n e d } } }
{ \displaystyle   \sigma   _ { y } ^ { 2 } = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } \left ( Y _ { i } - { \overline   { Y } } \right ) ^ { 2 } = \left ( { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } Y _ { i } ^ { 2 } \right ) - { \overline   { Y } } ^ { 2 } = { \frac   { 1 } { n ^ { 2 } } } \sum   _ { i , j \,:\,i < j } \left ( Y _ { i } - Y _ { j } \right ) ^ { 2 } . }
{ \overline   { Y } }
{ \displaystyle   { \overline   { Y } } = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } Y _ { i } . }
{ \overline   { Y } }
{ \displaystyle   \sigma   _ { Y } ^ { 2 } }
{ \displaystyle   \sigma   _ { Y } ^ { 2 } }
{ \displaystyle   { \begin { a l i g n e d } \operatorname   { E }   [ \sigma   _ { Y } ^ { 2 } ] & = \operatorname   { E }   \left [ { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } \left ( Y _ { i } - { \frac   { 1 } { n } } \sum   _ { j = 1 } ^ { n } Y _ { j } \right ) ^ { 2 } \right ] \\[5pt ] & = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } \operatorname   { E }   \left [ Y _ { i } ^ { 2 } - { \frac   { 2 } { n } } Y _ { i } \sum   _ { j = 1 } ^ { n } Y _ { j } + { \frac   { 1 } { n ^ { 2 } } } \sum   _ { j = 1 } ^ { n } Y _ { j } \sum   _ { k = 1 } ^ { n } Y _ { k } \right ] \\[5pt ] & = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } \left [ { \frac   { n - 2 } { n } } \operatorname   { E }   [ Y _ { i } ^ { 2 } ] - { \frac   { 2 } { n } } \sum   _ { j \neq   i } \operatorname   { E }   [ Y _ { i } Y _ { j } ] + { \frac   { 1 } { n ^ { 2 } } } \sum   _ { j = 1 } ^ { n } \sum   _ { k \neq   j } ^ { n } \operatorname   { E }   [ Y _ { j } Y _ { k } ] + { \frac   { 1 } { n ^ { 2 } } } \sum   _ { j = 1 } ^ { n } \operatorname   { E }   [ Y _ { j } ^ { 2 } ] \right ] \\[5pt ] & = { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } \left [ { \frac   { n - 2 } { n } } ( \sigma   ^ { 2 } + \mu   ^ { 2 } ) - { \frac   { 2 } { n } } ( n - 1 ) \mu   ^ { 2 } + { \frac   { 1 } { n ^ { 2 } } } n ( n - 1 ) \mu   ^ { 2 } + { \frac   { 1 } { n } } ( \sigma   ^ { 2 } + \mu   ^ { 2 } ) \right ] \\[5pt ] & = { \frac   { n - 1 } { n } } \sigma   ^ { 2 } . \end { a l i g n e d } } }
{ \displaystyle   \sigma   _ { Y } ^ { 2 } }
{ \frac   { n - 1 } { n } }
{ \displaystyle   \sigma   _ { Y } ^ { 2 } }
{ \displaystyle   s ^ { 2 } = { \frac   { n } { n - 1 } } \sigma   _ { Y } ^ { 2 } = { \frac   { n } { n - 1 } } \left ( { \frac   { 1 } { n } } \sum   _ { i = 1 } ^ { n } \left ( Y _ { i } - { \overline   { Y } } \right ) ^ { 2 } \right ) = { \frac   { 1 } { n - 1 } } \sum   _ { i = 1 } ^ { n } \left ( Y _ { i } - { \overline   { Y } } \right ) ^ { 2 } }
{ \displaystyle   ( n - 1 ) { \frac   { S ^ { 2 } } { \sigma   ^ { 2 } } } \sim   \chi   _ { n - 1 } ^ { 2 } . }
{ \displaystyle   \operatorname   { E }   ( S ^ { 2 } ) = \operatorname   { E }   \left ( { \frac   { \sigma   ^ { 2 } } { n - 1 } } \chi   _ { n - 1 } ^ { 2 } \right ) = \sigma   ^ { 2 } , }
{ \displaystyle   \operatorname   { V a r }   [ s ^ { 2 } ] = \operatorname   { V a r }   \left ( { \frac   { \sigma   ^ { 2 } } { n - 1 } } \chi   _ { n - 1 } ^ { 2 } \right ) = { \frac   { \sigma   ^ { 4 } } { ( n - 1 ) ^ { 2 } } } \operatorname   { V a r }   \left ( \chi   _ { n - 1 } ^ { 2 } \right ) = { \frac   { 2 \sigma   ^ { 4 } } { n - 1 } } . }
{ \displaystyle   \operatorname   { E }   [ S ^ { 2 } ] = \sigma   ^ { 2 } , \quad   \operatorname   { V a r }   [ S ^ { 2 } ] = { \frac   { \sigma   ^ { 4 } } { n } } \left ( ( \kappa   - 1 ) + { \frac   { 2 } { n - 1 } } \right ) = { \frac   { 1 } { n } } \left ( \mu   _ { 4 } - { \frac   { n - 3 } { n - 1 } } \sigma   ^ { 4 } \right ) , }
{ \displaystyle   { \bar   { y } } \pm   \sigma   _ { Y } ( n - 1 ) ^ { 1 / 2 } . }
\sigma   _ { y } ^ { 2 } \leq   2 y _ { \max   } ( A - H ) ,
\sigma   _ { y } ^ { 2 }
\sigma   _ { y } ^ { 2 } \leq   { \frac   { y _ { \max   } ( A - H ) ( y _ { \max   } - A ) } { y _ { \max   } - H } } ,
\sigma   _ { y } ^ { 2 } \geq   { \frac   { y _ { \min   } ( A - H ) ( A - y _ { \min   } ) } { H - y _ { \min   } } } ,
\sigma   _ { 1 }
\sigma   _ { 2 }
{ \sqrt   { \sigma   _ { 1 } ^ { 2 } + \sigma   _ { 2 } ^ { 2 } } }
\Sigma  
I = n ( \mathbf   { 1 }   _ { 3 \times   3 } \operatorname   { t r }   ( \Sigma   ) - \Sigma   ) .
\Sigma   = { \begin { b m a t r i x } 1 0 & 0 & 0 \\0 & 0 . 1 & 0 \\0 & 0 & 0 . 1 \end { b m a t r i x } } .
I = n { \begin { b m a t r i x } 0 . 2 & 0 & 0 \\0 & 1 0 . 1 & 0 \\0 & 0 & 1 0 . 1 \end { b m a t r i x } } .
x
{ \displaystyle   \mathbb   { C }   , }
{ \displaystyle   \operatorname   { E }   \left [ ( x - \mu   ) ( x - \mu   ) ^ { * } \right ] , }
x ^ { * }
x .
X
{ \displaystyle   \mathbb   { R }   ^ { n } , }
{ \displaystyle   \operatorname   { E }   \left [ ( X - \mu   ) ( X - \mu   ) ^ { \operatorname   { T }   } \right ] , }
\mu   = \operatorname   { E }   ( X )
X ^ { \operatorname   { T }   }
X ,
X
{ \displaystyle   \mathbb   { C }   ^ { n } , }
{ \displaystyle   \operatorname   { E }   \left [ ( X - \mu   ) ( X - \mu   ) ^ { \dagger   } \right ] , }
X ^ { \dagger   }
X .
X ,
{ \displaystyle   \operatorname   { E }   \left [ ( X - \mu   ) ^ { \operatorname   { T }   } ( X - \mu   ) \right ] = \operatorname   { t r }   ( C ) , }
