x _ { 1 }
x _ { 2 }
{ \displaystyle   l = \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 } + \beta   _ { 2 } x _ { 2 } , }
\beta   _ { i }
x _ { 1 }
x _ { 2 }
\beta   _ { 0 }
{ \displaystyle   o = b ^ { \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 } + \beta   _ { 2 } x _ { 2 } } }
{ \displaystyle   o = o : 1 }
{ \displaystyle   o / ( o + 1 ) }
{ \displaystyle   p = { \frac   { b ^ { \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 } + \beta   _ { 2 } x _ { 2 } } } { b ^ { \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 } + \beta   _ { 2 } x _ { 2 } } + 1 } } = { \frac   { 1 } { 1 + b ^ { - ( \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 } + \beta   _ { 2 } x _ { 2 } ) } } } }
{ \displaystyle   - 3 , 1 , 2 }
{ \displaystyle   l = - 3 + 1 \cdot   x _ { 1 } + 2 \cdot   x _ { 2 } , }
{ \displaystyle   \beta   _ { 0 } = - 3 }
- 3
{ \displaystyle   1 0 ^ { - 3 } = 1 0 ^ { - 3 } : 1 = 1 : 1 0 0 0 , }
{ \displaystyle   1 / ( 1 0 0 0 + 1 ) = 1 / 1 0 0 1 \approx   0 . 0 0 1 = 0 . 1 \ % }
{ \displaystyle   l ' = 1 \cdot   x _ { 1 } + 2 \cdot   x _ { 2 } , }
{ \displaystyle   l = l ' - 3 }
{ \displaystyle   - \beta   _ { 0 } }
{ \displaystyle   l ' = 1 \cdot   x _ { 1 } + 2 \cdot   x _ { 2 } = 3 , }
{ \displaystyle   1 0 ^ { 0 } = 1 0 ^ { 0 } : 1 = 1 : 1 , }
{ \displaystyle   1 / ( 1 + 1 ) = 1 / 2 = 5 0 \ % . }
{ \displaystyle   \beta   _ { 1 } = 1 }
x _ { 1 }
{ \displaystyle   1 \cdot   1 }
{ \displaystyle   1 0 ^ { 1 } = 1 0 ; }
x _ { 1 }
{ \displaystyle   \beta   _ { 2 } = 2 }
x _ { 2 }
{ \displaystyle   2 \cdot   1 }
{ \displaystyle   1 0 ^ { 2 } = 1 0 0 . }
x _ { 2 }
x _ { 1 }
x _ { 1 } , x _ { 2 }
x _ { 1 }
x _ { 2 }
{ \displaystyle   1 \cdot   3 = 3 , }
{ \displaystyle   1 0 ^ { 3 } = 1 0 0 0 , }
{ \displaystyle   2 \cdot   2 = 4 , }
{ \displaystyle   1 0 ^ { 4 } = 1 0 0 0 0 , }
{ \displaystyle   p = 0 . 0 1 6 7 }
{ \displaystyle   { \text { I n t e r c e p t } } = - 4 . 0 7 7 7 }
{ \displaystyle   { \text { H o u r s } } = 1 . 5 0 4 6 }
{ \displaystyle   { \begin { a l i g n e d } { \text { L o g - o d d s   o f   p a s s i n g   e x a m } } & = 1 . 5 0 4 6 \cdot   { \text { H o u r s } } - 4 . 0 7 7 7 = 1 . 5 0 4 6 \cdot   ( { \text { H o u r s } } - 2 . 7 1 ) \\{ \text { O d d s   o f   p a s s i n g   e x a m } } & = \exp   \left ( 1 . 5 0 4 6 \cdot   { \text { H o u r s } } - 4 . 0 7 7 7 \right ) = \exp   \left ( 1 . 5 0 4 6 \cdot   ( { \text { H o u r s } } - 2 . 7 1 ) \right ) \\{ \text { P r o b a b i l i t y   o f   p a s s i n g   e x a m } } & = { \frac   { 1 } { 1 + \exp   \left ( - \left ( 1 . 5 0 4 6 \cdot   { \text { H o u r s } } - 4 . 0 7 7 7 \right ) \right ) } } \end { a l i g n e d } } }
{ \displaystyle   \exp ( 1 . 5 0 4 6 ) \approx   4 . 5 . }
{ \displaystyle   { \text { H o u r s } } = 2 }
{ \displaystyle   { \text { P r o b a b i l i t y   o f   p a s s i n g   e x a m } } = { \frac   { 1 } { 1 + \exp   \left ( - \left ( 1 . 5 0 4 6 \cdot   2 - 4 . 0 7 7 7 \right ) \right ) } } = 0 . 2 6 }
{ \displaystyle   { \text { P r o b a b i l i t y   o f   p a s s i n g   e x a m } } = { \frac   { 1 } { 1 + \exp   \left ( - \left ( 1 . 5 0 4 6 \cdot   4 - 4 . 0 7 7 7 \right ) \right ) } } = 0 . 8 7 }
{ \displaystyle   p = 0 . 0 1 6 7 }
{ \displaystyle   p = 0 . 0 0 0 6 }
{ \displaystyle   \operatorname   { l o g i t }   p = \ln   { \frac   { p } { 1 - p } } \quad   { \text { f o r   } } 0 < p < 1 . }
{ \displaystyle   \operatorname   { l o g i t }   \operatorname   { E }   ( Y ) = \alpha   + \beta   x }
y \mid   x
\beta  
{ \displaystyle   y = { \begin { c a s e s } 1 & \beta   _ { 0 } + \beta   _ { 1 } x + \varepsilon   > 0 \\0 & { \text { e l s e } } \end { c a s e s } } }
\varepsilon  
{ \displaystyle   y ' = \beta   _ { 0 } + \beta   _ { 1 } x + \varepsilon   }
\varepsilon  
y '
y
x
\beta  
y
x
y
x
\sigma   ( t )
\sigma   ( t ) \in   ( 0 , 1 )
t
t
{ \displaystyle   t \in   \mathbb   { R }   }
\sigma   ( t )
\sigma   ( t ) = { \frac   { e ^ { t } } { e ^ { t } + 1 } } = { \frac   { 1 } { 1 + e ^ { - t } } }
t
x
t
t
t = \beta   _ { 0 } + \beta   _ { 1 } x
{ \displaystyle   p ( x ) = { \frac   { 1 } { 1 + e ^ { - ( \beta   _ { 0 } + \beta   _ { 1 } x ) } } } }
p ( x )
Y _ { i }
P ( Y _ { i } = 1 \mid   X )
X _ { i }
X
\beta  
g
{ \displaystyle   g ( p ( x ) ) = \operatorname   { l o g i t }   p ( x ) = \ln   \left ( { \frac   { p ( x ) } { 1 - p ( x ) } } \right ) = \beta   _ { 0 } + \beta   _ { 1 } x , }
{ \displaystyle   { \frac   { p ( x ) } { 1 - p ( x ) } } = e ^ { \beta   _ { 0 } + \beta   _ { 1 } x } . }
g
{ \displaystyle   g ( p ( x ) ) }
\ln  
p ( x )
p ( x )
p ( x )
\beta   _ { 0 }
\beta   _ { 1 } x
e
x
x
{ \text { o d d s } } = e ^ { \beta   _ { 0 } + \beta   _ { 1 } x } .
{ \displaystyle   \mathrm   { O R }   = { \frac   { \operatorname   { o d d s }   ( x + 1 ) } { \operatorname   { o d d s }   ( x ) } } = { \frac   { \left ( { \frac   { F ( x + 1 ) } { 1 - F ( x + 1 ) } } \right ) } { \left ( { \frac   { F ( x ) } { 1 - F ( x ) } } \right ) } } = { \frac   { e ^ { \beta   _ { 0 } + \beta   _ { 1 } ( x + 1 ) } } { e ^ { \beta   _ { 0 } + \beta   _ { 1 } x } } } = e ^ { \beta   _ { 1 } } }
\beta   _ { 1 }
e ^ { \beta   _ { 1 } }
{ \frac   { a d } { b c } }
\beta   _ { 0 } + \beta   _ { 1 } x
{ \displaystyle   \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 } + \beta   _ { 2 } x _ { 2 } + \cdots   + \beta   _ { m } x _ { m } = \beta   _ { 0 } + \sum   _ { i = 1 } ^ { m } \beta   _ { i } x _ { i } }
\beta   _ { j }
Y
\theta  
{ \displaystyle   h _ { \theta   } ( X ) = { \frac   { 1 } { 1 + e ^ { - \theta   ^ { T } X } } } = P r ( Y = 1 | X ; \theta   ) }
{ \displaystyle   P r ( Y = 0 | X ; \theta   ) = 1 - h _ { \theta   } ( X ) }
{ \displaystyle   Y \in   \{ 0 , 1 \},Pr ( y | X ; \theta   ) }
Y
{ \displaystyle   P r ( y \mid   X ; \theta   ) = h _ { \theta   } ( X ) ^ { y } ( 1 - h _ { \theta   } ( X ) ) ^ { ( 1 - y ) } }
{ \displaystyle   { \begin { a l i g n e d } L ( \theta   \mid   x ) & = \Pr ( Y \mid   X ; \theta   ) \\&=\prod   _ { i } \Pr ( y _ { i } \mid   x _ { i } ; \theta   ) \\&=\prod   _ { i } h _ { \theta   } ( x _ { i } ) ^ { y _ { i } } ( 1 - h _ { \theta   } ( x _ { i } ) ) ^ { ( 1 - y _ { i } ) } \end { a l i g n e d } } }
N ^ { { - 1 } }
{ \displaystyle   N ^ { - 1 } \log   L ( \theta   \mid   x ) = N ^ { - 1 } \sum   _ { i = 1 } ^ { N } \log   \Pr ( y _ { i } \mid   x _ { i } ; \theta   ) }
( x , y )
{ \displaystyle   { \begin { a l i g n e d } \lim   \limits   _ { N \rightarrow   + \infty   } N ^ { - 1 } \sum   _ { i = 1 } ^ { N } \log   P r ( y _ { i } \mid   x _ { i } ; \theta   ) & = \sum   _ { x \in   { \mathcal   { X } } } \sum   _ { y \in   { \mathcal   { Y } } } \Pr ( X = x , Y = y ) \log   P r ( Y = y \mid   X = x ; \theta   ) \\&=\sum   _ { x \in   { \mathcal   { X } } } \sum   _ { y \in   { \mathcal   { Y } } } \Pr ( X = x , Y = y ) \left ( - \log   { \frac   { P r ( Y = y \mid   X = x ) } { P r ( Y = y \mid   X = x ; \theta   ) } } + \log   \Pr ( Y = y \mid   X = x ) \right ) \\&=-D_ { \text { K L } } ( Y \parallel   Y _ { \theta   } ) - H ( Y \mid   X ) \end { a l i g n e d } } }
{ \displaystyle   H ( X \mid   Y ) }
{ \displaystyle   D _ { \text { K L } } }
k
p
{ \displaystyle   1 0 k / p }
y = 0
{ \displaystyle   y = 1 }
{ \displaystyle   \mathbf   { w }   ^ { T } = [ \beta   _ { 0 } , \beta   _ { 1 } , \beta   _ { 2 } , \ldots   ] }
{ \displaystyle   \mathbf   { x }   ( i ) = [ 1 , x _ { 1 } ( i ) , x _ { 2 } ( i ) , \ldots   ] ^ { T } }
{ \displaystyle   \mu   ( i ) = { \frac   { 1 } { 1 + e ^ { - \mathbf   { w }   ^ { T } \mathbf   { x }   ( i ) } } } }
\mathbf   { w }  
{ \displaystyle   \mathbf   { w }   _ { k + 1 } = \left ( \mathbf   { X }   ^ { T } \mathbf   { S }   _ { k } \mathbf   { X }   \right ) ^ { - 1 } \mathbf   { X }   ^ { T } \left ( \mathbf   { S }   _ { k } \mathbf   { X }   \mathbf   { w }   _ { k } + \mathbf   { y }   - \mathbf   { \boldsymbol   { \mu   } }   _ { k } \right ) }
{ \displaystyle   \mathbf   { S }   = \operatorname   { d i a g }   ( \mu   ( i ) ( 1 - \mu   ( i ) ) ) }
{ \displaystyle   { \boldsymbol   { \mu   } } = [ \mu   ( 1 ) , \mu   ( 2 ) , \ldots   ] }
{ \displaystyle   \mathbf   { X }   = { \begin { b m a t r i x } 1 & x _ { 1 } ( 1 ) & x _ { 2 } ( 1 ) & \ldots   \\1 & x _ { 1 } ( 2 ) & x _ { 2 } ( 2 ) & \ldots   \\\vdots   & \vdots   & \vdots   \end { b m a t r i x } } }
{ \displaystyle   \mathbf   { y }   ( i ) = [ y ( 1 ) , y ( 2 ) , \ldots   ] ^ { T } }
D = - 2 \ln   { \frac   { \text { l i k e l i h o o d   o f   t h e   f i t t e d   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } .
\chi   _ { s - p } ^ { 2 } ,
{ \displaystyle   { \begin { a l i g n e d } D _ { \text { n u l l } } & = - 2 \ln   { \frac   { \text { l i k e l i h o o d   o f   n u l l   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } \\[6pt ] D _ { \text { f i t t e d } } & = - 2 \ln   { \frac   { \text { l i k e l i h o o d   o f   f i t t e d   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } . \end { a l i g n e d } } }
{ \displaystyle   { \begin { a l i g n e d } D _ { \text { n u l l } } - D _ { \text { f i t t e d } } & = - 2 \left ( \ln   { \frac   { \text { l i k e l i h o o d   o f   n u l l   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } - \ln   { \frac   { \text { l i k e l i h o o d   o f   f i t t e d   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } \right ) \\[6pt ] & = - 2 \ln   { \frac   { \left ( { \dfrac   { \text { l i k e l i h o o d   o f   n u l l   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } \right ) } { \left ( { \dfrac   { \text { l i k e l i h o o d   o f   f i t t e d   m o d e l } } { \text { l i k e l i h o o d   o f   t h e   s a t u r a t e d   m o d e l } } } \right ) } } \\[6pt ] & = - 2 \ln   { \frac   { \text { l i k e l i h o o d   o f   t h e   n u l l   m o d e l } } { \text { l i k e l i h o o d   o f   f i t t e d   m o d e l } } } . \end { a l i g n e d } } }
R _ { \text { L } } ^ { 2 } = { \frac   { D _ { \text { n u l l } } - D _ { \text { f i t t e d } } } { D _ { \text { n u l l } } } } .
{ \displaystyle   { \begin { a l i g n e d } R _ { \text { C S } } ^ { 2 } & = 1 - \left ( { \frac   { L _ { M } } { L _ { 0 } } } \right ) ^ { 2 / n } \\[5pt ] & = 1 - e ^ { 2 ( \ln ( L _ { M } ) - \ln ( L _ { 0 } ) ) / n } \end { a l i g n e d } } }
1 - L _ { 0 } ^ { 2 / n }
{ \displaystyle   R _ { \text { M c F } } ^ { 2 } = 1 - { \frac   { \ln ( L _ { M } ) } { \ln   L _ { 0 } } } , }
{ \displaystyle   { \begin { m a t r i x } R _ { \text { C S } } ^ { 2 } = 1 - \left ( { \dfrac   { 1 } { L _ { 0 } } } \right ) ^ { \frac   { 2 ( R _ { \text { M c F } } ^ { 2 } ) } { n } } \\[1 . 5 e m ] R _ { \text { M c F } } ^ { 2 } = - { \dfrac   { n } { 2 } } \cdot   { \dfrac   { \ln ( 1 - R _ { \text { C S } } ^ { 2 } ) } { \ln   L _ { 0 } } } \end { m a t r i x } } }
\chi   ^ { 2 }
{ \displaystyle   W _ { j } = { \frac   { \beta   _ { j } ^ { 2 } } { S E _ { \beta   _ { j } } ^ { 2 } } } }
\beta   _ { j }
\beta   _ { 0 }
\beta   _ { 0 }
{ \displaystyle   { \hat   { \beta   _ { 0 } ^ { * } } } = { \widehat   { \beta   } } _ { 0 } + \log   { \frac   { \pi   } { 1 - \pi   } } - \log   { { \tilde   { \pi   } }   \over   { 1 - { \tilde   { \pi   } } } } }
\pi  
{ \tilde   { \pi   } }
{ \displaystyle   { \begin { a l i g n e d } Y _ { i } \mid   x _ { 1 , i } , \ldots   , x _ { m , i } \ &\sim   \operatorname   { B e r n o u l l i }   ( p _ { i } ) \\\operatorname   { E }   [ Y _ { i } \mid   x _ { 1 , i } , \ldots   , x _ { m , i } ] & = p _ { i } \\\Pr ( Y _ { i } = y \mid   x _ { 1 , i } , \ldots   , x _ { m , i } ) & = { \begin { c a s e s } p _ { i } & { \text { i f   } } y = 1 \\1 - p _ { i } & { \text { i f   } } y = 0 \end { c a s e s } } \\\Pr ( Y _ { i } = y \mid   x _ { 1 , i } , \ldots   , x _ { m , i } ) & = p _ { i } ^ { y } ( 1 - p _ { i } ) ^ { ( 1 - y ) } \end { a l i g n e d } } }
f ( i )
f ( i ) = \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 , i } + \cdots   + \beta   _ { m } x _ { m , i } ,
\beta   _ { 0 } , \ldots   , \beta   _ { m }
f ( i ) = { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ,
{ \displaystyle   \operatorname   { l o g i t }   ( \mathbb   { E }   [ Y _ { i } \mid   x _ { 1 , i } , \ldots   , x _ { m , i } ] ) = \operatorname   { l o g i t }   ( p _ { i } ) = \ln   \left ( { \frac   { p _ { i } } { 1 - p _ { i } } } \right ) = \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 , i } + \cdots   + \beta   _ { m } x _ { m , i } }
\operatorname   { l o g i t }   ( \mathbb   { E }   [ Y _ { i } \mid   \mathbf   { X }   _ { i } ] ) = \operatorname   { l o g i t }   ( p _ { i } ) = \ln   \left ( { \frac   { p _ { i } } { 1 - p _ { i } } } \right ) = { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i }
( - \infty   , + \infty   )
e ^ { \beta   }
\mathbb   { E }   [ Y _ { i } \mid   \mathbf   { X }   _ { i } ] = p _ { i } = \operatorname   { l o g i t }   ^ { - 1 } ( { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) = { \frac   { 1 } { 1 + e ^ { - { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } }
{ \displaystyle   \Pr ( Y _ { i } = y \mid   \mathbf   { X }   _ { i } ) = { p _ { i } } ^ { y } ( 1 - p _ { i } ) ^ { 1 - y } = \left ( { \frac   { e ^ { { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } { 1 + e ^ { { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } } \right ) ^ { y } \left ( 1 - { \frac   { e ^ { { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } { 1 + e ^ { { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } } \right ) ^ { 1 - y } = { \frac   { e ^ { { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } \cdot   y } } { 1 + e ^ { { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } } }
Y _ { i } ^ { \ast   } = { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } + \varepsilon   \ ,
\varepsilon   \sim   \operatorname   { L o g i s t i c }   ( 0 , 1 ) \ ,
Y _ { i } = { \begin { c a s e s } 1 & { \text { i f   } } Y _ { i } ^ { \ast   } > 0 \ { \text {   i . e .   } } - \varepsilon   < { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } , \\0 & { \text { o t h e r w i s e . } } \end { c a s e s } }
\Pr ( \varepsilon   < x ) = \operatorname   { l o g i t }   ^ { - 1 } ( x )
{ \begin { a l i g n e d } \Pr ( Y _ { i } = 1 \mid   \mathbf   { X }   _ { i } ) & = \Pr ( Y _ { i } ^ { \ast   } > 0 \mid   \mathbf   { X }   _ { i } ) & \\&=\Pr ( { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } + \varepsilon   > 0 ) & \\&=\Pr ( \varepsilon   > - { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) & \\&=\Pr ( \varepsilon   < { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) & & { \text { ( b e c a u s e   t h e   l o g i s t i c   d i s t r i b u t i o n   i s   s y m m e t r i c ) } } \\&=\operatorname   { l o g i t }   ^ { - 1 } ( { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) & \\&=p_ { i } & & { \text { ( s e e   a b o v e ) } } \end { a l i g n e d } }
{ \begin { a l i g n e d } Y _ { i } ^ { 0 \ast   } & = { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } + \varepsilon   _ { 0 } \,\\Y_ { i } ^ { 1 \ast   } & = { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } + \varepsilon   _ { 1 } \,\end { a l i g n e d } }
{ \begin { a l i g n e d } \varepsilon   _ { 0 } & \sim   \operatorname   { E V }   _ { 1 } ( 0 , 1 ) \\\varepsilon   _ { 1 } & \sim   \operatorname   { E V }   _ { 1 } ( 0 , 1 ) \end { a l i g n e d } }
\Pr ( \varepsilon   _ { 0 } = x ) = \Pr ( \varepsilon   _ { 1 } = x ) = e ^ { - x } e ^ { - e ^ { - x } }
Y _ { i } = { \begin { c a s e s } 1 & { \text { i f   } } Y _ { i } ^ { 1 \ast   } > Y _ { i } ^ { 0 \ast   } , \\0 & { \text { o t h e r w i s e . } } \end { c a s e s } }
{ \boldsymbol   { \beta   } } = { \boldsymbol   { \beta   } } _ { 1 } - { \boldsymbol   { \beta   } } _ { 0 }
\varepsilon   = \varepsilon   _ { 1 } - \varepsilon   _ { 0 }
\varepsilon   = \varepsilon   _ { 1 } - \varepsilon   _ { 0 } \sim   \operatorname   { L o g i s t i c }   ( 0 , 1 ) .
{ \displaystyle   { \begin { a l i g n e d } \Pr ( Y _ { i } = 1 \mid   \mathbf   { X }   _ { i } ) = { } & \Pr   \left ( Y _ { i } ^ { 1 \ast   } > Y _ { i } ^ { 0 \ast   } \mid   \mathbf   { X }   _ { i } \right ) & \\={ } & \Pr   \left ( Y _ { i } ^ { 1 \ast   } - Y _ { i } ^ { 0 \ast   } > 0 \mid   \mathbf   { X }   _ { i } \right ) & \\={ } & \Pr   \left ( { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } + \varepsilon   _ { 1 } - \left ( { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } + \varepsilon   _ { 0 } \right ) > 0 \right ) & \\={ } & \Pr   \left ( ( { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } - { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } ) + ( \varepsilon   _ { 1 } - \varepsilon   _ { 0 } ) > 0 \right ) & \\={ } & \Pr ( ( { \boldsymbol   { \beta   } } _ { 1 } - { \boldsymbol   { \beta   } } _ { 0 } ) \cdot   \mathbf   { X }   _ { i } + ( \varepsilon   _ { 1 } - \varepsilon   _ { 0 } ) > 0 ) & \\={ } & \Pr ( ( { \boldsymbol   { \beta   } } _ { 1 } - { \boldsymbol   { \beta   } } _ { 0 } ) \cdot   \mathbf   { X }   _ { i } + \varepsilon   > 0 ) & & { \text { ( s u b s t i t u t e   } } \varepsilon   { \text {   a s   a b o v e ) } } \\={ } & \Pr ( { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } + \varepsilon   > 0 ) & & { \text { ( s u b s t i t u t e   } } { \boldsymbol   { \beta   } } { \text {   a s   a b o v e ) } } \\={ } & \Pr ( \varepsilon   > - { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) & & { \text { ( n o w ,   s a m e   a s   a b o v e   m o d e l ) } } \\={ } & \Pr ( \varepsilon   < { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) & \\={ } & \operatorname   { l o g i t }   ^ { - 1 } ( { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } ) & \\={ } & p _ { i } \end { a l i g n e d } } }
{ \displaystyle   { \begin { a l i g n e d } \ln   \Pr ( Y _ { i } = 0 ) & = { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } - \ln   Z \\\ln   \Pr ( Y _ { i } = 1 ) & = { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } - \ln   Z \end { a l i g n e d } } }
- l n Z
{ \displaystyle   { \begin { a l i g n e d } \Pr ( Y _ { i } = 0 ) & = { \frac   { 1 } { Z } } e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } \\\Pr ( Y _ { i } = 1 ) & = { \frac   { 1 } { Z } } e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } \end { a l i g n e d } } }
Z = e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } }
{ \displaystyle   { \begin { a l i g n e d } \Pr ( Y _ { i } = 0 ) & = { \frac   { e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } } { e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } } \\\Pr ( Y _ { i } = 1 ) & = { \frac   { e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } { e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } } . \end { a l i g n e d } } }
\Pr ( Y _ { i } = c ) = { \frac   { e ^ { { \boldsymbol   { \beta   } } _ { c } \cdot   \mathbf   { X }   _ { i } } } { \sum   _ { h } e ^ { { \boldsymbol   { \beta   } } _ { h } \cdot   \mathbf   { X }   _ { i } } } }
\Pr ( Y _ { i } = c ) = \operatorname   { s o f t m a x }   ( c , { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } , { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } , \dots   ) .
\Pr ( Y _ { i } = 0 )
\Pr ( Y _ { i } = 1 )
\Pr ( Y _ { i } = 0 ) + \Pr ( Y _ { i } = 1 ) = 1
{ \displaystyle   { \begin { a l i g n e d } \Pr ( Y _ { i } = 1 ) & = { \frac   { e ^ { ( { \boldsymbol   { \beta   } } _ { 1 } + \mathbf   { C }   ) \cdot   \mathbf   { X }   _ { i } } } { e ^ { ( { \boldsymbol   { \beta   } } _ { 0 } + \mathbf   { C }   ) \cdot   \mathbf   { X }   _ { i } } + e ^ { ( { \boldsymbol   { \beta   } } _ { 1 } + \mathbf   { C }   ) \cdot   \mathbf   { X }   _ { i } } } } \\&={ \frac   { e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } e ^ { \mathbf   { C }   \cdot   \mathbf   { X }   _ { i } } } { e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } e ^ { \mathbf   { C }   \cdot   \mathbf   { X }   _ { i } } + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } e ^ { \mathbf   { C }   \cdot   \mathbf   { X }   _ { i } } } } \\&={ \frac   { e ^ { \mathbf   { C }   \cdot   \mathbf   { X }   _ { i } } e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } { e ^ { \mathbf   { C }   \cdot   \mathbf   { X }   _ { i } } ( e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } ) } } \\&={ \frac   { e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } { e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } } . \\\end { a l i g n e d } } }
{ \boldsymbol   { \beta   } } _ { 0 } = \mathbf   { 0 }   .
e ^ { { \boldsymbol   { \beta   } } _ { 0 } \cdot   \mathbf   { X }   _ { i } } = e ^ { \mathbf   { 0 }   \cdot   \mathbf   { X }   _ { i } } = 1
\Pr ( Y _ { i } = 1 ) = { \frac   { e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } { 1 + e ^ { { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } } = { \frac   { 1 } { 1 + e ^ { - { \boldsymbol   { \beta   } } _ { 1 } \cdot   \mathbf   { X }   _ { i } } } } = p _ { i }
{ \boldsymbol   { \beta   } } = { \boldsymbol   { \beta   } } _ { 1 } - { \boldsymbol   { \beta   } } _ { 0 }
p _ { i } = { \frac   { 1 } { 1 + e ^ { - ( \beta   _ { 0 } + \beta   _ { 1 } x _ { 1 , i } + \cdots   + \beta   _ { k } x _ { k , i } ) } } } . \ ,
y = { \frac   { 1 } { 1 + e ^ { - f ( X ) } } }
{ \frac   { \mathrm   { d }   y } { \mathrm   { d }   X } } = y ( 1 - y ) { \frac   { \mathrm   { d }   f } { \mathrm   { d }   X } } . \ ,
Y _ { i } \ \sim   \operatorname   { B i n }   ( n _ { i } , p _ { i } ) , { \text {   f o r   } } i = 1 , \dots   , n
p _ { i } = \mathbb   { E }   \left [ \left . { \frac   { Y _ { i } } { n _ { i } } } \,\right | \,\mathbf   { X }   _ { i } \right ] ,
{ \displaystyle   \operatorname   { l o g i t }   \left ( \mathbb   { E }   \left [ \left . { \frac   { Y _ { i } } { n _ { i } } } \,\right | \,\mathbf   { X }   _ { i } \right ] \right ) = \operatorname   { l o g i t }   ( p _ { i } ) = \ln   \left ( { \frac   { p _ { i } } { 1 - p _ { i } } } \right ) = { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } , }
{ \displaystyle   \Pr ( Y _ { i } = y \mid   \mathbf   { X }   _ { i } ) = { n _ { i }   \choose   y } p _ { i } ^ { y } ( 1 - p _ { i } ) ^ { n _ { i } - y } = { n _ { i }   \choose   y } \left ( { \frac   { 1 } { 1 + e ^ { - { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } } \right ) ^ { y } \left ( 1 - { \frac   { 1 } { 1 + e ^ { - { \boldsymbol   { \beta   } } \cdot   \mathbf   { X }   _ { i } } } } \right ) ^ { n _ { i } - y } . }
\sigma   ( x )
\Phi   ( { \sqrt   { \frac   { \pi   } { 8 } } } x )
